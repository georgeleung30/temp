{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "386d7887-1523-40da-b76f-f76ca7688c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "from seqeval.metrics.sequence_labeling import get_entities, performance_measure\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "from crf import CRFInference\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68de39a7-1f50-4409-b2d8-4e55af7f0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    set_seed\n",
    ")\n",
    "from utils import (\n",
    "    convert_examples_to_features,\n",
    "    read_examples_from_file,\n",
    "    BertForTokenClassification,\n",
    "    get_labels, filtered_tp_counts)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from unittest.mock import MagicMock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33e95394-0920-45a7-81cc-21dc370d9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seeds(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "def finetune_support(args, model, tokenizer, labels, pad_token_label_id):\n",
    "    previous_score = 1e+6 # infinity placeholder\n",
    "    sup_dataset = read_and_load_examples(args, tokenizer, labels, pad_token_label_id, mode=args.support_path,\n",
    "                                            mergeB=True)\n",
    "    sampler = SequentialSampler(sup_dataset)\n",
    "    dataloader = DataLoader(sup_dataset, sampler=sampler, batch_size=len(sup_dataset))\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate_finetuning, eps=args.adam_epsilon)\n",
    "    # Train!\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    rep_index = -1\n",
    "\n",
    "    set_seeds(args)\n",
    "    while(True):\n",
    "        rep_index += 1\n",
    "        epoch_iterator = tqdm(dataloader, desc=\"Iteration\", disable=True)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            # here loss can be either KL, or euclidean.\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1],\n",
    "                      \"token_type_ids\": batch[2], \"labels\": batch[3],\n",
    "                      \"loss_type\": args.finetune_loss,\n",
    "                      \"consider_mutual_O\": args.consider_mutual_O}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            # logger.info(\"finetune loss at repetition \"+ str(rep_index) + \" : \" + str(loss.item()))\n",
    "            loss.backward()\n",
    "            tr_loss += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        if loss.item() > previous_score:\n",
    "            # early stopping with single step patience\n",
    "            break\n",
    "\n",
    "        previous_score = loss.item()\n",
    "\n",
    "def train(args, train_dataset, model):\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "\n",
    "    if args.num_train_epochs > 0:\n",
    "        t_total = len(train_dataloader) * args.num_train_epochs\n",
    "    else:\n",
    "        t_total = 0\n",
    "\n",
    "    # Prepare optimizer and schedule (decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
    "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "\n",
    "    # Train!\n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    training_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=False\n",
    "    )\n",
    "    set_seeds(args)  # Added here for reproductibility\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False )\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1],\n",
    "                      \"token_type_ids\": batch[2], \"labels\": batch[3],\"loss_type\":args.training_loss,\n",
    "                      \"consider_mutual_O\": args.consider_mutual_O}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            loss.backward()\n",
    "            training_loss += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "                # TODO remove args.save_steps\n",
    "    return global_step, training_loss / global_step if global_step > 0 else 0\n",
    "\n",
    "def extract_target_labels(args, dataset, model):\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=args.eval_batch_size)\n",
    "    vecs = None\n",
    "    vecs_mu = None\n",
    "    vecs_sigma = None\n",
    "    labels = None\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader, desc=\"Support representations\"):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        label_batch = batch[3]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1],\n",
    "                      \"token_type_ids\": batch[2]}\n",
    "            outputs = model(**inputs)\n",
    "            output_embed_mu = outputs[0]\n",
    "            output_embed_sigma = outputs[1]\n",
    "            hidden_states = outputs[2]\n",
    "\n",
    "        if vecs_mu is None:\n",
    "            vecs = hidden_states.detach().cpu().numpy()\n",
    "            vecs_mu = output_embed_mu.detach().cpu().numpy()\n",
    "            vecs_sigma = output_embed_sigma.detach().cpu().numpy()\n",
    "            labels = label_batch.detach().cpu().numpy()\n",
    "        else:\n",
    "            vecs = np.append(vecs, hidden_states.detach().cpu().numpy(), axis=0)\n",
    "            vecs_mu = np.append(vecs_mu, output_embed_mu.detach().cpu().numpy(), axis=0)\n",
    "            vecs_sigma = np.append(vecs_sigma, output_embed_sigma.detach().cpu().numpy(), axis=0)\n",
    "            labels = np.append(labels, label_batch.detach().cpu().numpy(), axis=0)\n",
    "    _, _, hidden_size = vecs_mu.shape\n",
    "    _, _, hidden_bert_size = vecs.shape\n",
    "    vecs, vecs_mu, vecs_sigma, labels = vecs.reshape(-1, hidden_bert_size), vecs_mu.reshape(-1, hidden_size), vecs_sigma.reshape(-1, hidden_size), labels.reshape(-1)\n",
    "    fil_vecs, fil_vecs_mu, fil_vecs_sigma, fil_labels = [], [], [], []\n",
    "    for vec, vec_mu, vec_sigma, label in zip(vecs, vecs_mu, vecs_sigma, labels):\n",
    "        if label == CrossEntropyLoss().ignore_index:\n",
    "            continue\n",
    "        fil_vecs.append(vec)\n",
    "        fil_vecs_mu.append(vec_mu)\n",
    "        fil_vecs_sigma.append(vec_sigma)\n",
    "        fil_labels.append(label)\n",
    "    vecs, vecs_mu, vecs_sigma, labels = torch.tensor(fil_vecs).to(args.device), torch.tensor(fil_vecs_mu).to(args.device), torch.Tensor(fil_vecs_sigma).to(args.device), torch.tensor(fil_labels).to(args.device)\n",
    "    return vecs_mu.view(-1, hidden_size), vecs_sigma.view(-1, hidden_size), vecs.view(-1, hidden_bert_size), labels.view(-1)\n",
    "\n",
    "def entitywise_max(scores, tags, addone=0, num_labels = None):\n",
    "    # scores: n x m\n",
    "    # tags: m\n",
    "    # return: n x t\n",
    "    n, m = scores.shape\n",
    "    if num_labels == None:\n",
    "        max_tag = torch.max(tags) + 1\n",
    "    else:\n",
    "        max_tag = num_labels # extra 1 is not needed since it's already 1 based counting\n",
    "    ret = -100000. * torch.ones(n, max_tag+addone).to(scores.device)\n",
    "    for t in range(addone, max_tag+addone):\n",
    "        mask = (tags == (t-addone)).float().view(1, -1)\n",
    "        masked = scores * mask\n",
    "        masked = torch.where(masked < 0, masked, torch.tensor(-100000.).to(scores.device))\n",
    "        ret[:, t] = torch.max(masked, dim=1)[0]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def nearest_neighbor(args, rep_mus, rep_sigmas, rep_hidden_states, support_rep_mus, support_rep_sigmas, support_rep, support_tags, evaluation_criteria, num_labels):\n",
    "    \"\"\"\n",
    "    Neariest neighbor decoder for the best named entity tag sequences\n",
    "    \"\"\"\n",
    "    batch_size, sent_len, ndim = rep_mus.shape\n",
    "    _, _, ndim_bert = rep_hidden_states.shape\n",
    "    if evaluation_criteria == \"KL\":\n",
    "        scores = _loss_kl(rep_mus.view(-1, ndim), rep_sigmas.view(-1,ndim), support_rep_mus, support_rep_sigmas, ndim)\n",
    "        tags = support_tags[torch.argmin(scores, 1)]\n",
    "\n",
    "    elif evaluation_criteria == \"euclidean\":\n",
    "        scores = _euclidean_metric(rep_mus.view(-1, ndim), support_rep_mus, True)\n",
    "        tags = support_tags[torch.argmax(scores, 1)]\n",
    "\n",
    "    elif evaluation_criteria == \"euclidean_hidden_state\":\n",
    "        scores = _euclidean_metric(rep_hidden_states.view(-1, ndim_bert), support_rep, True)\n",
    "        tags = support_tags[torch.argmax(scores, 1)]\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Unknown decoding criteria detected. Please =specify KL/ euclidean/ euclidean_hidden_state\")\n",
    "\n",
    "    if args.temp_trans > 0:\n",
    "        scores = entitywise_max(scores, support_tags, 1, num_labels)\n",
    "        max_scores, tags = torch.max(scores, 1)\n",
    "        tags = tags - 1\n",
    "\n",
    "    return tags.view(batch_size, sent_len), scores.view(batch_size, sent_len, -1)\n",
    "\n",
    "def _euclidean_metric(a, b, normalize=False):\n",
    "    if normalize:\n",
    "        a = F.normalize(a)\n",
    "        b = F.normalize(b)\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b) ** 2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "def _loss_kl(mu_i, sigma_i, mu_j, sigma_j, embed_dimension):\n",
    "    n = mu_i.shape[0]\n",
    "    m = mu_j.shape[0]\n",
    "\n",
    "    mu_i = mu_i.unsqueeze(1).expand(n,m, -1)\n",
    "    sigma_i = sigma_i.unsqueeze(1).expand(n,m,-1)\n",
    "    mu_j = mu_j.unsqueeze(0).expand(n,m,-1)\n",
    "    sigma_j = sigma_j.unsqueeze(0).expand(n,m,-1)\n",
    "    sigma_ratio = sigma_j / sigma_i\n",
    "    trace_fac = torch.sum(sigma_ratio, 2)\n",
    "    log_det = torch.sum(torch.log(sigma_ratio + 1e-14), axis=2)\n",
    "    mu_diff_sq = torch.sum((mu_i - mu_j) ** 2 / sigma_i, axis=2)\n",
    "    ij_kl = 0.5 * (trace_fac + mu_diff_sq - embed_dimension - log_det)\n",
    "    sigma_ratio = sigma_i / sigma_j\n",
    "    trace_fac = torch.sum(sigma_ratio, 2)\n",
    "    log_det = torch.sum(torch.log(sigma_ratio + 1e-14), axis=2)\n",
    "    mu_diff_sq = torch.sum((mu_j - mu_i) ** 2 / sigma_j, axis=2)\n",
    "    ji_kl = 0.5 * (trace_fac + mu_diff_sq - embed_dimension - log_det)\n",
    "    kl_d = 0.5 * (ij_kl + ji_kl)\n",
    "    return kl_d\n",
    "\n",
    "\n",
    "def evaluate(args, model, tokenizer, labels, pad_token_label_id, mode, prefix=\"\"):\n",
    "    sup_dataset = read_and_load_examples(args, tokenizer, labels, pad_token_label_id, mode=args.support_path, mergeB=True)\n",
    "    sup_mus, sup_sigmas, sups, sup_labels = extract_target_labels(args, sup_dataset, model)\n",
    "    eval_dataset = read_and_load_examples(args, tokenizer, labels, pad_token_label_id, mode=mode, mergeB=True)\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        label_batch = batch[3]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1],\n",
    "                      \"token_type_ids\": batch[2]}\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs[2]\n",
    "            output_embedding_mu = outputs[0]\n",
    "            output_embedding_sigma = outputs[1]\n",
    "\n",
    "            nn_predictions, nn_scores = nearest_neighbor(args, output_embedding_mu, output_embedding_sigma, hidden_states, sup_mus, sup_sigmas, sups, sup_labels, evaluation_criteria=args.evaluation_criteria, num_labels=len(labels))\n",
    "        if preds is None:\n",
    "            preds = nn_predictions.detach().cpu().numpy()\n",
    "            scores = nn_scores.detach().cpu().numpy()\n",
    "            out_label_ids = label_batch.detach().cpu().numpy()\n",
    "\n",
    "        else:\n",
    "            preds = np.append(preds, nn_predictions.detach().cpu().numpy(), axis=0)\n",
    "            scores = np.append(scores, nn_scores.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, label_batch.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    merged_labels = [label for label in labels if not label.startswith('I-')]\n",
    "    conv_labels = []\n",
    "    for label in merged_labels:\n",
    "        if label.startswith('B-'):\n",
    "            conv_labels.append('I-' + label[2:])\n",
    "        else:\n",
    "            conv_labels.append(label)\n",
    "    label_map = {i: label for i, label in enumerate(conv_labels)}\n",
    "\n",
    "    out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "    scores_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "    preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "\n",
    "    for i in range(out_label_ids.shape[0]):\n",
    "        for j in range(out_label_ids.shape[1]):\n",
    "            if out_label_ids[i, j] != pad_token_label_id:\n",
    "                out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "                scores_list[i].append(scores[i][j])\n",
    "                preds_list[i].append(label_map[preds[i][j]])\n",
    "\n",
    "    if args.temp_trans > 0:\n",
    "        # START: Viterbi!!!\n",
    "        vit_preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        crf = CRFInference(len(label_map) + 1, args.trans_priors, args.temp_trans)\n",
    "        for i in range(out_label_ids.shape[0]):\n",
    "            sent_scores = torch.tensor(scores_list[i])\n",
    "            sent_probs = F.softmax(sent_scores, dim=1)\n",
    "            sent_len, n_tag = sent_probs.shape\n",
    "            feats = crf.forward(torch.log(sent_probs).view(1, sent_len, n_tag))\n",
    "            vit_tags = crf.viterbi(feats)\n",
    "            vit_tags = vit_tags.view(sent_len)\n",
    "            vit_tags = vit_tags.detach().cpu().numpy()\n",
    "            for tag in vit_tags:\n",
    "                vit_preds_list[i].append(label_map[tag - 1])\n",
    "        preds_list = vit_preds_list\n",
    "        # END\n",
    "\n",
    "    performance_dict = performance_measure(out_label_list, preds_list)\n",
    "    pred_sum, tp_sum, true_sum = filtered_tp_counts(out_label_list, preds_list)\n",
    "    results = {\n",
    "        \"precision\": precision_score(out_label_list, preds_list),\n",
    "        \"recall\": recall_score(out_label_list, preds_list),\n",
    "        \"f1\": f1_score(out_label_list, preds_list),\n",
    "        \"TP\": performance_dict['TP'],\n",
    "        \"TN\": performance_dict['TN'],\n",
    "        \"FP\": performance_dict['FP'],\n",
    "        \"FN\": performance_dict['FN'],\n",
    "        \"pred_sum\": pred_sum,\n",
    "        \"tp_sum\": tp_sum,\n",
    "        \"true_sum\": true_sum\n",
    "    }\n",
    "\n",
    "    logger.info(\"***** Eval results %s *****\", prefix)\n",
    "    for key in sorted(results.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "\n",
    "    return results, preds_list\n",
    "\n",
    "\n",
    "def read_and_load_examples(args, tokenizer, labels, pad_token_label_id, mode, mergeB=False):\n",
    "    examples = read_examples_from_file(args.data_dir, mode)\n",
    "    features, label_map = convert_examples_to_features(\n",
    "        examples,\n",
    "        labels,\n",
    "        args.max_seq_length,\n",
    "        tokenizer,\n",
    "        cls_token_at_end=False,\n",
    "        cls_token=tokenizer.cls_token,\n",
    "        cls_token_segment_id=0,\n",
    "        sep_token=tokenizer.sep_token,\n",
    "        sep_token_extra=False,\n",
    "        pad_on_left=False,\n",
    "        pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "        pad_token_segment_id=0,\n",
    "        pad_token_label_id\n",
    "        =pad_token_label_id,\n",
    "        mergeB=mergeB,\n",
    "    )\n",
    "\n",
    "    # Convert to Tensors\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def trans_stats(args, labels):\n",
    "    '''\n",
    "\n",
    "    Reference: https://aclanthology.org/2020.emnlp-main.516.pdf\n",
    "    '''\n",
    "    tag_lists = get_tags(args.data_dir + '/train.txt', labels, True)\n",
    "    s_o, s_i = 0., 0.\n",
    "    o_o, o_i = 0., 0.\n",
    "    i_o, i_i, x_y = 0., 0., 0.\n",
    "    for tags in tag_lists:\n",
    "        if tags[0] == 'O': s_o += 1\n",
    "        else: s_i += 1\n",
    "        for i in range(len(tags)-1):\n",
    "            p, n = tags[i], tags[i+1]\n",
    "            if p == 'O':\n",
    "                if n == 'O': o_o += 1\n",
    "                else: o_i += 1\n",
    "            else:\n",
    "                if n == 'O':\n",
    "                    i_o += 1\n",
    "                elif p != n:\n",
    "                    x_y += 1\n",
    "                else:\n",
    "                    i_i += 1\n",
    "    ret = []\n",
    "    ret.append(s_o / (s_o + s_i))\n",
    "    ret.append(s_i / (s_o + s_i))\n",
    "    ret.append(o_o / (o_o + o_i))\n",
    "    ret.append(o_i / (o_o + o_i))\n",
    "    ret.append(i_o / (i_o + i_i + x_y))\n",
    "    ret.append(i_i / (i_o + i_i + x_y))\n",
    "    ret.append(x_y / (i_o + i_i + x_y))\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_tags(fname, labels, to_I=False):\n",
    "    tag_lists = []\n",
    "    tag_list = []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"-DOCSTART-\") or line.strip() == \"\":\n",
    "                if tag_list:\n",
    "                    tag_lists.append(tag_list)\n",
    "                    tag_list = []\n",
    "            else:\n",
    "                splits = line.split()\n",
    "                if len(splits) > 1:\n",
    "                    tag = splits[1]\n",
    "                    if tag not in labels:\n",
    "                        tag = 'O'\n",
    "                    if to_I and tag.startswith('B-'):\n",
    "                        tag = 'I-' + tag[2:]\n",
    "                    tag_list.append(tag)\n",
    "        if tag_list:\n",
    "            tag_lists.append(tag_list)\n",
    "\n",
    "    return tag_lists\n",
    "\n",
    "\n",
    "def convert_examples_to_features(\n",
    "        examples,\n",
    "        label_list,\n",
    "        max_seq_length,\n",
    "        tokenizer,\n",
    "        cls_token_at_end=False,\n",
    "        cls_token=\"[CLS]\",\n",
    "        cls_token_segment_id=1,\n",
    "        sep_token=\"[SEP]\",\n",
    "        sep_token_extra=False,\n",
    "        pad_on_left=False,\n",
    "        pad_token=0,\n",
    "        pad_token_segment_id=0,\n",
    "        pad_token_label_id=-100,\n",
    "        sequence_a_segment_id=0,\n",
    "        mask_padding_with_zero=True,\n",
    "        mergeB=False,\n",
    "):\n",
    "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = defaultdict(int)\n",
    "    if not mergeB:\n",
    "        for i, label in enumerate(label_list):\n",
    "            label_map[label] = i\n",
    "    else:\n",
    "        i = 0\n",
    "        for label in label_list:\n",
    "            if label.startswith('B-') or label.startswith('I-'):\n",
    "                label_str = 'I-' + label[2:]\n",
    "                if label_str not in label_map:\n",
    "                    label_map[label_str] = i\n",
    "                    i += 1\n",
    "                label_map[label] = label_map[label_str]\n",
    "            else:\n",
    "                label_map[label] = i\n",
    "                i += 1\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in tqdm(enumerate(examples)):\n",
    "\n",
    "        tokens = []\n",
    "        label_ids = []\n",
    "        for word, label in zip(example.words, example.labels):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            if len(word_tokens) == 0:\n",
    "                continue\n",
    "            tokens.extend(word_tokens)\n",
    "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        special_tokens_count = 3 if sep_token_extra else 2\n",
    "        if len(tokens) > max_seq_length - special_tokens_count:\n",
    "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
    "            label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids:   0   0   0   0  0     0   0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens += [sep_token]\n",
    "        label_ids += [pad_token_label_id]\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens += [cls_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "            segment_ids += [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            label_ids = [pad_token_label_id] + label_ids\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "        assert len(tokens) == len(label_ids), str(tokens) + \" vs\" + str(label_ids)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
    "        else:\n",
    "            input_ids += [pad_token] * padding_length\n",
    "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
    "            segment_ids += [pad_token_segment_id] * padding_length\n",
    "            label_ids += [pad_token_label_id] * padding_length\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids)\n",
    "        )\n",
    "    return features, label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7940846d-e197-470b-9e8e-b1060c3e392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_arg:\n",
    "    def __init__(self):\n",
    "        self.test = 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5ab782b-5055-47c2-b2a2-b090a189ad2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "args = test_arg()\n",
    "args.data_dir = 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\few-nerd\\\\inter\\\\'\n",
    "args.labels_train = 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\CONTaiNER\\\\data\\\\few-nerd\\\\inter\\\\labels_train.txt' \n",
    "args.labels_test = 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\CONTaiNER\\\\data\\\\few-nerd\\\\inter\\\\labels_test.txt'\n",
    "args.model_name_or_path = 'bert-base-uncased'\n",
    "args.config_name = None\n",
    "args.tokenizer_name = ''\n",
    "args.do_train = True\n",
    "args.do_predict = True\n",
    "\n",
    "\n",
    "args.saved_model_dir = './test_save/' \n",
    "args.output_dir = './test_output/'\n",
    "args.cache_dir = './cache/'\n",
    "\n",
    "args.max_seq_length = 128 \n",
    "args.embedding_dimension = 128 \n",
    "args.num_train_epochs = 1 \n",
    "args.train_batch_size = 16\n",
    "args.weight_decay = 0\n",
    "args.adam_epsilon = 1e-8\n",
    "\n",
    "args.max_grad_norm = 1.0\n",
    "args.learning_rate = 5e-5\n",
    "args.training_loss = 'KL'\n",
    "args.finetune_loss = 'KL'\n",
    "args.evaluation_criteria = 'euclidean_hidden_state'\n",
    "args.n_shots = 5\n",
    "args.consider_mutual_O = 'store_true'\n",
    "args.learning_rate_finetuning =5e-5\n",
    "args.silent = 'store_true'\n",
    "args.temp_trans = 0.01\n",
    "args.do_finetune_support_only = True\n",
    "args.overwrite_output_dir = 'store_true'\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "args.device = torch.device(\"cuda:0\")\n",
    "args.no_cuda = False\n",
    "args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
    "args.n_gpu = min(1, args.n_gpu) # we are keeping ourselves restricted to only 1 gpu\n",
    "args.best_validation_f1 = -1\n",
    "args.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "614b5484-9eff-41c4-8fae-7611ebd43627",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = test_arg()\n",
    "args.data_dir = 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\2018_n2c2\\\\few_nerd_format\\\\'\n",
    "args.labels_train = 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\2018_n2c2\\\\few_nerd_format\\\\labels_train.txt' \n",
    "args.labels_test = 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\2018_n2c2\\\\few_nerd_format\\\\labels_test.txt'\n",
    "args.model_name_or_path = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'\n",
    "args.config_name = None\n",
    "args.tokenizer_name = ''\n",
    "args.do_train = True\n",
    "args.do_predict = True\n",
    "\n",
    "\n",
    "args.saved_model_dir = './test_save/' \n",
    "args.output_dir = './test_output/'\n",
    "args.cache_dir = './cache/'\n",
    "\n",
    "args.max_seq_length = 128 \n",
    "args.embedding_dimension = 128 \n",
    "args.num_train_epochs = 10\n",
    "args.train_batch_size = 16\n",
    "args.weight_decay = 0\n",
    "args.adam_epsilon = 1e-8\n",
    "\n",
    "args.max_grad_norm = 1.0\n",
    "args.learning_rate = 5e-5\n",
    "args.training_loss = 'KL'\n",
    "args.finetune_loss = 'KL'\n",
    "args.evaluation_criteria = 'euclidean_hidden_state'\n",
    "args.n_shots = 5\n",
    "args.consider_mutual_O = 'store_true'\n",
    "args.learning_rate_finetuning =5e-5\n",
    "args.silent = 'store_true'\n",
    "args.temp_trans = 0.01\n",
    "args.do_finetune_support_only = True\n",
    "args.overwrite_output_dir = 'store_true'\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "args.device = torch.device(\"cuda:0\")\n",
    "args.no_cuda = False\n",
    "args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
    "args.n_gpu = min(1, args.n_gpu) # we are keeping ourselves restricted to only 1 gpu\n",
    "args.best_validation_f1 = -1\n",
    "args.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28514fea-766c-4e2d-a44f-4a2023c14edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91869a6f-c297-4619-90e3-7adb0e9ab79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2023 23:05:13 - WARNING - __main__ -   Device: cuda:0, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger.warning(\n",
    "    \"Device: %s, n_gpu: %s\",\n",
    "    args.device,\n",
    "    args.n_gpu,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d521899-2c7a-4aec-8c9b-45a8a7906e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(args)\n",
    "labels_train = get_labels(args.labels_train)\n",
    "labels_test = get_labels(args.labels_test)\n",
    "num_labels = len(labels_train)\n",
    "pad_token_label_id = CrossEntropyLoss().ignore_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06142bd0-8176-430b-945e-2461cfde14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a84c7f-6d2c-4ba8-8e65-440eb335555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['output_embedder_mu.1.bias', 'projection.0.bias', 'output_embedder_sigma.1.weight', 'output_embedder_mu.1.weight', 'projection.0.weight', 'output_embedder_sigma.1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = BertConfig.from_pretrained(\n",
    "        args.config_name if args.config_name else args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        id2label={str(i): label for i, label in enumerate(labels_train)},\n",
    "        label2id={label: i for i, label in enumerate(labels_train)},\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "        task_specific_params={\"embedding_dimension\": args.embedding_dimension}\n",
    "    )\n",
    "TOKENIZER_ARGS = [\"do_lower_case\", \"strip_accents\", \"keep_accents\", \"use_fast\"]\n",
    "\n",
    "tokenizer_args = {k: v for k, v in vars(args).items() if v is not None and k in TOKENIZER_ARGS}\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    **tokenizer_args,\n",
    ")\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f89951-2270-4707-be50-3aad0867ba3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2023 23:05:21 - INFO - __main__ -   Training/evaluation parameters <__main__.test_arg object at 0x00000207A60FE820>\n"
     ]
    }
   ],
   "source": [
    "model.to(args.device)\n",
    "logger.info(\"Training/evaluation parameters %s\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb57979-df70-482b-a781-25810c7fa5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training\n",
    "# if args.do_train:\n",
    "#     train_dataset = read_and_load_examples(args, tokenizer, labels_train, pad_token_label_id, mode=\"train\", mergeB=True)\n",
    "#     torch.save(train_dataset, 'train_dataset_n2c2.pt')\n",
    "\n",
    "# train_dataset = torch.load('train_dataset.pt')\n",
    "train_dataset = torch.load('train_dataset_n2c2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94fe2276-93ed-476e-a8e0-7db08e143a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                              | 0/2598 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|                                                                      | 1/2598 [00:00<10:55,  3.96it/s]\u001b[A\n",
      "Iteration:   0%|                                                                      | 2/2598 [00:00<08:38,  5.00it/s]\u001b[A\n",
      "Iteration:   0%|                                                                      | 3/2598 [00:00<07:59,  5.41it/s]\u001b[A\n",
      "Iteration:   0%|                                                                      | 4/2598 [00:00<07:53,  5.48it/s]\u001b[A\n",
      "Iteration:   0%|▏                                                                     | 5/2598 [00:03<45:31,  1.05s/it]\u001b[A\n",
      "Iteration:   0%|▏                                                                     | 6/2598 [00:03<33:55,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|▏                                                                     | 7/2598 [00:03<25:52,  1.67it/s]\u001b[A\n",
      "Iteration:   0%|▏                                                                     | 8/2598 [00:04<20:08,  2.14it/s]\u001b[A\n",
      "Iteration:   0%|▏                                                                     | 9/2598 [00:04<17:24,  2.48it/s]\u001b[A\n",
      "Iteration:   0%|▎                                                                    | 10/2598 [00:04<14:55,  2.89it/s]\u001b[A\n",
      "Iteration:   0%|▎                                                                    | 11/2598 [00:04<13:04,  3.30it/s]\u001b[A\n",
      "Iteration:   0%|▎                                                                    | 12/2598 [00:04<11:25,  3.77it/s]\u001b[A\n",
      "Iteration:   1%|▎                                                                    | 13/2598 [00:05<10:19,  4.17it/s]\u001b[A\n",
      "Iteration:   1%|▎                                                                    | 14/2598 [00:05<09:52,  4.36it/s]\u001b[A\n",
      "Iteration:   1%|▍                                                                    | 15/2598 [00:05<10:44,  4.00it/s]\u001b[A\n",
      "Iteration:   1%|▍                                                                    | 16/2598 [00:05<10:22,  4.14it/s]\u001b[A\n",
      "Iteration:   1%|▍                                                                    | 17/2598 [00:06<10:18,  4.18it/s]\u001b[A\n",
      "Iteration:   1%|▍                                                                    | 18/2598 [00:06<12:20,  3.49it/s]\u001b[A\n",
      "Iteration:   1%|▌                                                                    | 19/2598 [00:06<11:15,  3.82it/s]\u001b[A\n",
      "Iteration:   1%|▌                                                                    | 20/2598 [00:06<10:10,  4.23it/s]\u001b[A\n",
      "Iteration:   1%|▌                                                                    | 21/2598 [00:07<10:28,  4.10it/s]\u001b[A\n",
      "Iteration:   1%|▌                                                                    | 22/2598 [00:07<09:50,  4.36it/s]\u001b[A\n",
      "Iteration:   1%|▌                                                                    | 23/2598 [00:07<09:54,  4.33it/s]\u001b[A\n",
      "Iteration:   1%|▋                                                                    | 24/2598 [00:07<10:23,  4.13it/s]\u001b[A\n",
      "Iteration:   1%|▋                                                                    | 25/2598 [00:07<09:37,  4.46it/s]\u001b[A\n",
      "Iteration:   1%|▋                                                                    | 26/2598 [00:08<09:35,  4.47it/s]\u001b[A\n",
      "Iteration:   1%|▋                                                                    | 27/2598 [00:08<09:38,  4.44it/s]\u001b[A\n",
      "Iteration:   1%|▋                                                                    | 28/2598 [00:08<09:19,  4.60it/s]\u001b[A\n",
      "Iteration:   1%|▊                                                                    | 29/2598 [00:08<09:18,  4.60it/s]\u001b[A\n",
      "Iteration:   1%|▊                                                                    | 30/2598 [00:09<10:22,  4.13it/s]\u001b[A\n",
      "Iteration:   1%|▊                                                                    | 31/2598 [00:12<17:15,  2.48it/s]\u001b[A\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m global_step, tr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m global_step = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, average loss = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, global_step, tr_loss)\n",
      "Cell \u001b[1;32mIn[33], line 110\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args, train_dataset, model)\u001b[0m\n\u001b[0;32m    105\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[0;32m    106\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    107\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch[\u001b[38;5;241m3\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:args\u001b[38;5;241m.\u001b[39mtraining_loss,\n\u001b[0;32m    108\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsider_mutual_O\u001b[39m\u001b[38;5;124m\"\u001b[39m: args\u001b[38;5;241m.\u001b[39mconsider_mutual_O}\n\u001b[1;32m--> 110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    113\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[1;32m~\\Documents\\container_ner\\CONTaiNER\\src\\utils.py:193\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, loss_type, consider_mutual_O)\u001b[0m\n\u001b[0;32m    190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (original_embedding_mu, original_embedding_sigma,) \u001b[38;5;241m+\u001b[39m (outputs[\u001b[38;5;241m0\u001b[39m],) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_KL_or_euclidean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_embedding_mu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43moriginal_embedding_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsider_mutual_O\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (loss,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\Documents\\container_ner\\CONTaiNER\\src\\utils.py:86\u001b[0m, in \u001b[0;36mcalculate_KL_or_euclidean\u001b[1;34m(self, attention_mask, original_embedding_mu, original_embedding_sigma, labels, consider_mutual_O, loss_type)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_KL_or_euclidean\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_mask, original_embedding_mu, original_embedding_sigma, labels,\n\u001b[0;32m     78\u001b[0m                               consider_mutual_O\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, loss_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     79\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m#                   | repeat     |||                   | repeat\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# extract only active parts that does not contain any paddings\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     output_embedding_mu, output_embedding_sigma, labels_straightened \u001b[38;5;241m=\u001b[39m \u001b[43mremove_irrelevant_tokens_for_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43moriginal_embedding_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_embedding_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# remove indices with zero labels, that is \"O\" classes\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m consider_mutual_O:\n",
      "File \u001b[1;32m~\\Documents\\container_ner\\CONTaiNER\\src\\utils.py:61\u001b[0m, in \u001b[0;36mremove_irrelevant_tokens_for_loss\u001b[1;34m(self, attention_mask, original_embedding_mu, original_embedding_sigma, labels)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_irrelevant_tokens_for_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_mask, original_embedding_mu, original_embedding_sigma, labels):\n\u001b[0;32m     60\u001b[0m     active_indices \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 61\u001b[0m     active_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     63\u001b[0m     output_embedding_mu \u001b[38;5;241m=\u001b[39m original_embedding_mu\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dimension)[active_indices]\n\u001b[0;32m     64\u001b[0m     output_embedding_sigma \u001b[38;5;241m=\u001b[39m original_embedding_sigma\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dimension)[active_indices]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step, tr_loss = train(args, train_dataset, model)\n",
    "logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "415c0840-a10c-4c98-9849-66ccad98b5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\hf_ner_example\\\\container_bert_best_10ep\\\\tokenizer_config.json',\n",
       " 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\hf_ner_example\\\\container_bert_best_10ep\\\\special_tokens_map.json',\n",
       " 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\hf_ner_example\\\\container_bert_best_10ep\\\\vocab.txt',\n",
       " 'C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\hf_ner_example\\\\container_bert_best_10ep\\\\added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\hf_ner_example\\\\container_bert_best_10ep\\\\\")\n",
    "tokenizer.save_pretrained(\"C:\\\\Users\\\\George\\\\Documents\\\\container_ner\\\\hf_ner_example\\\\container_bert_best_10ep\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "80a22a44-0aa1-448c-b0ca-2303be9ab677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2023 13:29:35 - INFO - __main__ -   Saving model checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "if args.do_train:\n",
    "    # Create output directory if needed\n",
    "    if args.saved_model_dir is not None:\n",
    "        if not os.path.exists(args.saved_model_dir):\n",
    "            os.makedirs(args.saved_model_dir)\n",
    "\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "\n",
    "    logger.info(\"Saving model checkpoint\")\n",
    "\n",
    "    model_to_save = (\n",
    "        model.module if hasattr(model, \"module\") else model\n",
    "    )\n",
    "    if args.saved_model_dir is None:\n",
    "        model_to_save.save_pretrained(args.output_dir)\n",
    "        tokenizer.save_pretrained(args.output_dir)\n",
    "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "    else:\n",
    "        model_to_save.save_pretrained(args.saved_model_dir)\n",
    "        tokenizer.save_pretrained(args.saved_model_dir)\n",
    "        torch.save(args, os.path.join(args.saved_model_dir, \"training_args.bin\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa9ede-51f8-4670-9a09-8cfed284f705",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96e27fc6-0647-48d5-8c3c-a0c27913ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict, Counter\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b10d69d6-f7ee-4cd3-8f80-6f3b3f75a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, label in zip(example.words, example.labels):\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    if len(word_tokens) == 0:\n",
    "        continue\n",
    "    tokens.extend(word_tokens)\n",
    "    # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "    label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "310c23c3-e3d0-4612-a281-5c4e268b6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = read_examples_from_file(args.data_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c72e3c6c-564b-4cc8-844f-adf18d7f6660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130112it [03:50, 563.97it/s]\n"
     ]
    }
   ],
   "source": [
    "features, label_map = convert_examples_to_features(\n",
    "    examples,\n",
    "    labels_train,\n",
    "    args.max_seq_length,\n",
    "    tokenizer,\n",
    "    cls_token_at_end=False,\n",
    "    cls_token=tokenizer.cls_token,\n",
    "    cls_token_segment_id=0,\n",
    "    sep_token=tokenizer.sep_token,\n",
    "    sep_token_extra=False,\n",
    "    pad_on_left=False,\n",
    "    pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "    pad_token_segment_id=0,\n",
    "    pad_token_label_id\n",
    "    =pad_token_label_id,\n",
    "    mergeB=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "415d09e9-4294-4034-a085-ed3639979ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeB = True\n",
    "label_list = labels_train\n",
    "max_seq_length = args.max_seq_length\n",
    "cls_token_at_end=False\n",
    "cls_token=tokenizer.cls_token\n",
    "cls_token_segment_id=0\n",
    "sep_token=tokenizer.sep_token\n",
    "sep_token_extra=False\n",
    "pad_on_left=False\n",
    "pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]\n",
    "pad_token_segment_id=0\n",
    "pad_token_label_id=pad_token_label_id\n",
    "sequence_a_segment_id=0\n",
    "mask_padding_with_zero=True\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "\n",
    "\n",
    "label_map = defaultdict(int)\n",
    "if not mergeB:\n",
    "    for i, label in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "else:\n",
    "    i = 0\n",
    "    for label in label_list:\n",
    "        if label.startswith('B-') or label.startswith('I-'):\n",
    "            label_str = 'I-' + label[2:]\n",
    "            if label_str not in label_map:\n",
    "                label_map[label_str] = i\n",
    "                i += 1\n",
    "            label_map[label] = label_map[label_str]\n",
    "        else:\n",
    "            label_map[label] = i\n",
    "            i += 1\n",
    "\n",
    "features = []\n",
    "\n",
    "ex_index = 50778\n",
    "example = examples[ex_index]\n",
    "\n",
    "# for (ex_index, example) in tqdm(enumerate(examples)):\n",
    "\n",
    "tokens = []\n",
    "label_ids = []\n",
    "for word, label in zip(example.words, example.labels):\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    if len(word_tokens) == 0:\n",
    "        continue\n",
    "    tokens.extend(word_tokens)\n",
    "    # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "    label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
    "\n",
    "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "special_tokens_count = 3 if sep_token_extra else 2\n",
    "if len(tokens) > max_seq_length - special_tokens_count:\n",
    "    tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
    "    label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
    "\n",
    "# The convention in BERT is:\n",
    "# (a) For sequence pairs:\n",
    "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "# (b) For single sequences:\n",
    "#  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "#  type_ids:   0   0   0   0  0     0   0\n",
    "#\n",
    "# Where \"type_ids\" are used to indicate whether this is the first\n",
    "# sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "# `type=1` were learned during pre-training and are added to the wordpiece\n",
    "# embedding vector (and position vector). This is not *strictly* necessary\n",
    "# since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "# it easier for the model to learn the concept of sequences.\n",
    "#\n",
    "# For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "# used as as the \"sentence vector\". Note that this only makes sense because\n",
    "# the entire model is fine-tuned.\n",
    "tokens += [sep_token]\n",
    "label_ids += [pad_token_label_id]\n",
    "if sep_token_extra:\n",
    "    # roberta uses an extra separator b/w pairs of sentences\n",
    "    tokens += [sep_token]\n",
    "    label_ids += [pad_token_label_id]\n",
    "segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "if cls_token_at_end:\n",
    "    tokens += [cls_token]\n",
    "    label_ids += [pad_token_label_id]\n",
    "    segment_ids += [cls_token_segment_id]\n",
    "else:\n",
    "    tokens = [cls_token] + tokens\n",
    "    label_ids = [pad_token_label_id] + label_ids\n",
    "    segment_ids = [cls_token_segment_id] + segment_ids\n",
    "assert len(tokens) == len(label_ids), str(tokens) + \" vs\" + str(label_ids)\n",
    "# input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "# # tokens are attended to.\n",
    "# input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "# # Zero-pad up to the sequence length.\n",
    "# padding_length = max_seq_length - len(input_ids)\n",
    "# if pad_on_left:\n",
    "#     input_ids = ([pad_token] * padding_length) + input_ids\n",
    "#     input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "#     segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "#     label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
    "# else:\n",
    "#     input_ids += [pad_token] * padding_length\n",
    "#     input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
    "#     segment_ids += [pad_token_segment_id] * padding_length\n",
    "#     label_ids += [pad_token_label_id] * padding_length\n",
    "\n",
    "# assert len(input_ids) == max_seq_length\n",
    "# assert len(input_mask) == max_seq_length\n",
    "# assert len(segment_ids) == max_seq_length\n",
    "# assert len(label_ids) == max_seq_length\n",
    "\n",
    "\n",
    "# features.append(\n",
    "#     InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0cf37401-a7c6-4f7c-b49d-92e59bb5bccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f23560b-79a3-44a7-ae52-168dfbc0566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d984bc-e0ca-4ce5-9bcd-5aba2e369389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
